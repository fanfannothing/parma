
# the details of this file are in flux
# if you're unclear, please talk to travis

# the set of valid keys and their documentation is not
# distributed throughout the project. they are mostly
# designed to be locally-relevant, i.e. you can make your
# own keys and everyone doesn't need to know what they do
# unless they are really diving into the details of your
# code (at which time they will have to find/figure out
# these keys).
# I think this aspect of parma is sub-optimal; it would
# be nice to have a centralized registry of what all
# these settings do. For now that registry will be this
# file: when you add a key, please document it as best you
# can and give an example valid value

# NOTE: if you see a relative path and the JVM cannot
# find the file, make sure that the root for the relative
# path is in the classpath
# (e.g. add /home/hltcoe/twolfe/miniScale2013/parma to your classpath)


#### location of input data ####
data.eecb.annotations.inline = /home/hltcoe/twolfe/scale2013/parma-data/eecb/docs/raw/
data.eecb.concrete.documents = /home/hltcoe/twolfe/scale2013/parma-data/eecb/eecb-docs-concrete.pb
data.eecb.concrete.alignments = /home/hltcoe/twolfe/scale2013/parma-data/eecb/eecb-alignments.concrete.pb

data.roth_frank.annotations = /home/hltcoe/twolfe/scale2013/parma-data/roth_frank/stand_off_predicates_and_annotations.cleaned.txt
data.roth_frank.concrete.documents = /home/hltcoe/twolfe/scale2013/parma-data/roth_frank/rf-docs-concrete.pb
data.roth_frank.concrete.alignments = /home/hltcoe/twolfe/scale2013/parma-data/roth_frank/rf-alignments.concrete.pb

data.least-overlap.reports = /home/hltcoe/twolfe/scale2013/parma-data/least-overlap/f1.concrete.pb
data.least-overlap.passages = /home/hltcoe/twolfe/scale2013/parma-data/least-overlap/f2.concrete.pb
data.least-overlap.alignments = /home/hltcoe/twolfe/scale2013/parma-data/least-overlap/alignments.xml

data.ldc.multiple-translations = /home/hltcoe/twolfe/miniScale2013/parma/data/least-overlap/

# used in EECBConverter and RothFrankConverter
# specifies where to dump the output of serializing DocAlignments in Concrete format
data.conversion.output = /home/hltcoe/twolfe/scale2013/parma-data/conversion.pb

# used by ConcreteDocReader to specify where to read DocAlignments from
data.concrete.input = /home/hltcoe/twolfe/scale2013/parma-data/concrete-conversion.pb


# what experiment should we run?
# see edu.jhu.hlt.parma.experiment.ExperimentImplTravis for implementations
experiments = EECBCVExperiment


# if any of these key-values don't exist, parma will skip over these diagnostics
diagnostics.parameter.outdir = diagnostics/parameters/
diagnostics.predictions.bad = diagnostics/predictions.bad.txt
diagnostics.predictions.all = diagnostics/predictions.all.txt
diagnostics.alignments.mturk = diagnostics/alignments/
diagnostics.profile.file = diagnostics/profile_times.txt
diagnostics.canonical.mention.file = diagnostics/canonical_mentions.txt
diagnostics.features.outdir = diagnostics/alignment_features
diagnostics.features.serialize = diagnostics/features
diagnostics.lexical-overlap-perf = diagnostics/overlap-vs-performance/
diagnostics.serialize.model = diagnostics/ham.model.jobj

# settings for inference
inference.ham.useHinge = true
inference.ham.L2penalty = 10.0
inference.ham.learningRate = 0.01
inference.ham.normalize.features = false



# tells the pipeline which features to use
# make sure that you provide at least one function that directly implements
# AlignmentSimilarityFunction (rather than a finer grained one like VerbPair),
# which will be called for all examples so that no empty vectors are produced
# for ablation, use features.ablate = SomeFeatureClassName (see edu.jhu.hlt.parma.features.FeatureLoader)

features = Intercept LemmaMatch CountFeatures SentenceContext JaroWinklerSimilarityFeature \
	PositionalFeatures ReportingVerbs Appositive TEDAlignment TransducerSimilarityFeature generic.ConciseFeaturesSlow


# if you would like an easy way to ablate features, do so here
#features.ablate = NumericSimilarity


# give this keyword a list of feature functions that you
# want to split their feature-space for
# e.g. lets say you have a feature "foo" that you
# think will work well on predicates, but not arguments,
# then do features = ... foo ...
# and features.split.predarg = ... foo ...
# and parma will wrap all of foo's features as
# "predicate-foo" = 0.8 vs "argument-foo" = 0.8
# this causes the inference engine to learn different
# parameters for your feature depending on if it fires
# in the context of a predicate pair or an argument pair
# @see edu.jhu.hlt.parma.inference.FeatureFunctionRefiner
# @see edu.jhu.hlt.parma.features.FeatureLoader
features.split.predarg = all

# this is another method for splitting features
# the original idea was to have either more specific
# or possibly overlapping classes of mention pairs
# that features would fire on. maybe arguments isn't
# specific enough for your feature, so you note that
# edu.jhu.hlt.parma.util.MentionClassifier will classify
# your mention pair as either a common noun or named
# entity mention pair. this option will split your
# feature into difference sub-spaces for these classifications
# @see edu.jhu.hlt.parma.inference.FeatureFunctionRefiner
# @see edu.jhu.hlt.parma.util.MentionClassifier
# @see edu.jhu.hlt.parma.features.FeatureLoader
#features.split.classifier = ppdb





# %h means home directory
java.util.logging.FileHandler.pattern= %h/parma.log

## Specify the handlers to create in the root logger
## (all loggers are children of the root logger)
## The following creates two handlers
handlers = java.util.logging.ConsoleHandler, java.util.logging.FileHandler
#handlers = java.util.logging.ConsoleHandler
    
## Set the default logging level for the root logger
.level = ALL
    
## Set the default logging level for new ConsoleHandler instances
#java.util.logging.ConsoleHandler.level = INFO
java.util.logging.ConsoleHandler.level = CONFIG

## Set the default formatter for new ConsoleHandler instances
java.util.logging.ConsoleHandler.formatter = java.util.logging.SimpleFormatter
    
## Set the default logging level for new FileHandler instances
## Note: ProcessStream supports setting a new path for the log file
#java.util.logging.FileHandler.level = ALL
java.util.logging.FileHandler.formatter = java.util.logging.SimpleFormatter
## java.util.logging.FileHandler.pattern=%h/Jerboa/logs/java%u.log

## Limiting size of output file in bytes: 
java.util.logging.FileHandler.limit = 50000

# Number of output files to cycle through, by appending an 
# integer to the base file name: 
java.util.logging.FileHandler.count = 10


features.biu = /home/hltcoe/twolfe/scale2013/parma-data/biu_string_rules.txt

# Wordnet dictionary datapath
features.wordnet.datapath = /home/hltcoe/twolfe/miniScale2013/parma/data/wordnet/dict

# maximum distance for wordnet synonyms, hypernyms and hyponyms
# this determines the size of the feature vector
features.wordnet.maxdistance = 2

# PPDB debugging (3000 line random sample)
features.ppdb.datapath = /home/hltcoe/jsnyder/Intersession_2013/lemmatized.v0.2-sample3000.phrasal
# PPDB small file datapath (800MB)
#features.ppdb.datapath = /home/hltcoe/jsnyder/Intersession_2013/lemmatized.v0.2-xl.phrasal
# PPDB large file (6.5G)
#features.ppdb.datapath = /home/hltcoe/jsnyder/Intersession_2013/v0.2-full.phrasal

features.wikirules.terms = /home/hltcoe/twolfe/miniScale2013/parma/data/wikirules/terms.csv
features.wikirules.rules = /home/hltcoe/twolfe/miniScale2013/parma/data/wikirules/rules.csv
features.wikirules.ruleCounts = /home/hltcoe/twolfe/miniScale2013/parma/data/wikirules/rules_counts.csv

# Name entity context similarity features file idfs
features.nameentity.contextmatch = /home/hltcoe/twolfe/miniScale2013/parma/data/idfs.txt

# FrameNet datapaths
features.framenet.predtoframes_datapath = /home/hltcoe/twolfe/miniScale2013/parma/data/framenet/predicateToFrameList.txt
features.framenet.frametopreds_datapath = /home/hltcoe/twolfe/miniScale2013/parma/data/framenet/frameToPredicateList.txt
features.framenet.frametoparents_datapath = /home/hltcoe/twolfe/miniScale2013/parma/data/framenet/frameToParentList.txt
features.framenet.frametochildren_datapath = /home/hltcoe/twolfe/miniScale2013/parma/data/framenet/frameToChildList.txt
features.framenet.frametoperspectiveparents_datapath = /home/hltcoe/twolfe/miniScale2013/parma/data/framenet/frameToPerspectiveParentList.txt
features.framenet.frametoperspectivechildren_datapath = /home/hltcoe/twolfe/miniScale2013/parma/data/framenet/frameToPerspectiveChildList.txt

# maximum distance for framenet frame relations: parent, child, perspective parent, perspective child
features.framenet.maxdistance = 3

#Verb Entailment datapath
features.verbentailmentannotated.datapath = /home/hltcoe/jdeyoung/projects/miniscale-2013/data/VerbEntailmentAnnotated.csv

#Phrase Entailment datapath
features.phrase.entailments.datapath = /home/hltcoe/jdeyoung/projects/miniscale-2013/data/PhraseEntailments/entailingAnnotations.txt,/home/hltcoe/jdeyoung/projects/miniscale-2013/data/PhraseEntailments/nonEntailingAnnotations.txt
#Phrase Entailment ignore headers
features.phrase.entailments.ignore.headers = true,true

features.reporting_verbs.acu = /home/hltcoe/twolfe/miniScale2013/parma/data/reporting_verbs/acu.lemmas.txt
features.reporting_verbs.adelaide = /home/hltcoe/twolfe/miniScale2013/parma/data/reporting_verbs/adelaide.lemmas.txt
features.reporting_verbs.misc = /home/hltcoe/twolfe/miniScale2013/parma/data/reporting_verbs/misc-stopwords.txt


# Nick's transducer's files
features.transducer.model = /home/hltcoe/nandrews/coref/parma_models/wiki_backoff_25000.ser

# Topic model for comparing contexts
features.topicJS.lda.model = /home/hltcoe/nandrews/coref/parma_models/lda.model

# experimental
# (for storing PPDB in redis)
features.ppdb.redis.file.syntax = null
#features.ppdb.redis.file.lexical = /home/hltcoe/twolfe/scale2013/parma-data/ppdb/v0.2-xxl.lexical
features.ppdb.redis.file.lexical = /home/hltcoe/twolfe/scale2013/parma-data/ppdb/release/v1.0/eng/xxxl/ppdb-1.0-eng-xxxl.lexical.gz
features.ppdb.redis.host = r6n1
features.ppdb.redis.port = 6379

BF.bloomIn = /export/common/SCALE13/Text/parma-data/redis.bf
BF.bloomOut = /export/common/SCALE13/Text/parma-data/redis.bf



